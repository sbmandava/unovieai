
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://unovie.ai/docs/blog/category/genai/">
      
      
        <link rel="prev" href="../../">
      
      
        <link rel="next" href="../market-trends/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.28">
    
    
      
        <title>GENAI - UnoVie.AI Engineering Blogs</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#genai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="UnoVie.AI Engineering Blogs" class="md-header__button md-logo" aria-label="UnoVie.AI Engineering Blogs" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            UnoVie.AI Engineering Blogs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              GENAI
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="/index.html" class="md-tabs__link">
        
  
    
  
  HOME

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="/solutions.html" class="md-tabs__link">
        
  
    
  
  SOLUTIONS

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="/service.html" class="md-tabs__link">
        
  
    
  
  SERVICES

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  BLOG

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="/about.html" class="md-tabs__link">
        
  
    
  
  ABOUT

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../capability/fe100/" class="md-tabs__link">
          
  
    
  
  Platform

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="UnoVie.AI Engineering Blogs" class="md-nav__button md-logo" aria-label="UnoVie.AI Engineering Blogs" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    UnoVie.AI Engineering Blogs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HOME
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="/solutions.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SOLUTIONS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="/service.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SERVICES
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    BLOG
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            BLOG
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    
      
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    GENAI
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    GENAI
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#apple-intelligence" class="md-nav__link">
    <span class="md-ellipsis">
      Apple Intelligence
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-vision-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      GPT Vision Transformer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-genai-mis-usecases" class="md-nav__link">
    <span class="md-ellipsis">
      Google GenAI Mis UseCases
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#google-naptime-ai-vulnerability" class="md-nav__link">
    <span class="md-ellipsis">
      Google NapTime AI Vulnerability
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#microsoft-ai-graphrag" class="md-nav__link">
    <span class="md-ellipsis">
      Microsoft AI GraphRAG
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../market-trends/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Market Trends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../medtech/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MedTech
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../platform-engineering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Platform Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../security/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Security
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="/about.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ABOUT
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Platform
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Platform
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../capability/fe100/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Edge-AI FarEdge FE100.
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../capability/gw200/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EdgeAI Gateway GW200.
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../capability/dc300/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EdgeAI DataCenter DC300.
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="genai">GENAI</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-07-21 00:00:00">Sunday, July 21, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">GENAI</a>, 
              <a href="../security/" class="md-meta__link">Security</a></li>
        
        
          
          <li class="md-meta__item">
            
              6 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="apple-intelligence"><a class="toclink" href="../../2024/07/21/apple-intelligence/">Apple Intelligence</a></h2>
<h3 id="apple-intelligence-on-device-processing"><a class="toclink" href="../../2024/07/21/apple-intelligence/#apple-intelligence-on-device-processing">Apple Intelligence : On Device Processing</a></h3>
<p><strong>Edge-AI Privacy Innovation / Security Blueprint from Apple WWDC24 Conference</strong></p>
<p>Apple WWDC24 Keynote has some amazing GENAI Edge Innovation and brilliant engineering science on display which they talked about how on-device models that can outsource to Apple’s servers. Most notable is their approach to features that don’t work with an on-device model.</p>
<p><img alt="Apple Private Cloud Compute" src="/blogs/assets/AppleAI.png" /></p>
<p><a href="https://www.youtube.com/watch?v=RXeOiIDNNek">Apple WWDC24 Keynote : Apple Intelligence Reference</a>
YouTube video at 1h14m43s </p>
<div class="admonition apple-intelligence">
<p class="admonition-title">Apple-intelligence</p>
<p>When you make a request, Apple Intelligence analysis whether it can be processed on device. If it needs greater computational capacity, it can draw on Private Cloud Compute, and send only the data that’s relevant to your task to be processed on Apple Silicon servers.</p>
<p>Your data is never stored or made accessible to Apple. It’s used exclusively to fulfill your request. And just like your iPhone, independent experts can inspect the code that runs on the servers to verify this privacy promise.</p>
<p>In fact, Private Cloud Compute cryptographically ensures your iPhone, iPad, and Mac will refuse to talk to a server unless its software has been publicly logged for inspection.</p>
<p>This sets a brand new standard on Privacy and AI</p>
</div>

    
      <nav class="md-post__action">
        <a href="../../2024/07/21/apple-intelligence/">
          Continue reading
        </a>
      </nav>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-07-19 00:00:00">Friday, July 19, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">GENAI</a>, 
              <a href="../medtech/" class="md-meta__link">MedTech</a></li>
        
        
          
          <li class="md-meta__item">
            
              6 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="gpt-vision-transformer"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/">GPT Vision Transformer</a></h2>
<h4 id="vision-ai-in-healthcare-streamlining-processes-and-empowering-decisions"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#vision-ai-in-healthcare-streamlining-processes-and-empowering-decisions">Vision AI in Healthcare: Streamlining Processes and Empowering Decisions</a></h4>
<p>Let's explores the transformative potential of Vision AI, specifically Vision GPT, in revolutionizing healthcare operations.</p>
<h4 id="understanding-vision-gpt"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#understanding-vision-gpt">Understanding Vision GPT</a></h4>
<p>Vision GPT is a powerful pre-trained model that seamlessly integrates computer vision and natural language processing (NLP). It leverages a transformer architecture to analyze both visual and textual data simultaneously, unlocking a deeper understanding of the relationship between them.</p>
<p><center>
<img alt="Vision Transformer" src="/blogs/assets/video-gpt.png" />
</center>
<center>Vision Transformer Capabilities </center></p>
<p>While existing large vision models excel in transfer learning, they often struggle when faced with various tasks and simple instructions. The challenge lies in handling spatial hierarchy and semantic granularity inherent in diverse vision-related tasks.</p>
<p>Key challenges include the limited availability of comprehensive visual annotations and the absence of a unified pretraining framework with a singular neural network architecture seamlessly integrating spatial hierarchy and semantic granularity. Existing datasets tailored for specialized applications heavily rely on human labeling, which limits, the development of foundational models capable of capturing the intricacies of vision-related tasks.</p>
<h4 id="vision-models"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#vision-models">Vision Models</a></h4>
<p><strong>Phi-3-Vision-128K-instruct</strong></p>
<p>Microsoft recently released Phi-3, a powerful language model, with a new Vision-Language variant called Phi-3-vision-128k-instruct. This 4B parameter model achieved impressive results on public benchmarks, even surpassing GPT-4V in some cases and outperforming Gemini 1.0 Pro V in all but MMMU.</p>
<p><strong>FaceBook-Chmeleon</strong>
Chameleon 🦎 by Meta is a unique model: it attempts to scale early fusion 🤨 But what is early fusion? Modern vision language models use a vision encoder with a projection layer to project image embeddings so it can be promptable to text decoder (LLM)</p>
<p>Early fusion on the other hand attempts to fuse all features together (image patches and text) by using an image tokenizer and all tokens are projected into a shared space, which enables seamless generation 😏  Authors have also introduced different architectural improvements (QK norm and revise placement of layer norms) for scalable and stable training and they were able to increase the token count (5x tokens compared to Llama 3 which is a must with early-fusion IMO)</p>
<p>This model is an any-to-any model thanks to early fusion: it can take image and text input and output image and text, but image generation are disabled to prevent malicious use. </p>
<p>One can also do text-only prompting, authors noted the model catches up with larger LLMs (like Mixtral 8x7B or larger Llama-2 70B) and also image-pair prompting with larger VLMs like IDEFICS2-80B</p>
<p><strong>Florence-2</strong></p>
<p>Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks. Florence-2 can interpret simple text prompts to perform tasks like captioning, object detection, and segmentation. It leverages our FLD-5B dataset, containing 5.4 billion annotations across 126 million images, to master multi-task learning. The model's sequence-to-sequence architecture enables it to excel in both zero-shot and fine-tuned settings, proving to be a competitive vision foundation model.
<center>
<img alt="Florence2 Vision" src="/blogs/assets/florence2-arch.png" />
</center>
<center>Florence 2 Vision Architecture </center></p>
<p>Built by Microsoft, the Florence-2 model adopts a sequence-to-sequence architecture, integrating an image encoder and a multi-modality encoder-decoder. This design accommodates a spectrum of vision tasks without the need for task-specific architectural modifications, aligning with the ethos of the NLP community for versatile model development with a consistent underlying structure.</p>
<p><center>
<img alt="Florence2 Vision" src="/blogs/assets/florence2-cap.png" />
</center>
<center>A general vision model must be able to operate at various degrees of granularity, both spatial and semantic</center></p>
<p>Florence-2 stands out through its unprecedented zero-shot and fine-tuning capabilities, achieving new state-of-the-art results in tasks such as captioning, object detection, visual grounding, and referring expression comprehension. Even after fine-tuning with public human-annotated data, Florence-2 competes with larger specialist models, establishing new benchmarks. </p>
<h4 id="key-capabilities"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#key-capabilities">Key Capabilities:</a></h4>
<p><strong>Object Recognition:</strong> Identifies objects within images (e.g., medical equipment, tumors, handwritten notes) using convolutional neural networks (CNNs) and transformer models.</p>
<p><img alt="Florence2 Vision" src="/blogs/assets/florence2-inf.png" /></p>
<p><strong>Semantic Understanding:</strong> Connects visual concepts with corresponding words or phrases, accurately interpreting descriptions of scenes and objects.</p>
<p><img alt="Florence2 Vision" src="/blogs/assets/florence2-inf3.png" /></p>
<p><strong>Contextual Reasoning:</strong> Analyzes the context surrounding objects in images, discerning nuances often missed by traditional computer vision models.</p>
<p><img alt="Florence2 Vision" src="/blogs/assets/florence2-inf4.png" /></p>
<h4 id="transforming-healthcare-processes"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#transforming-healthcare-processes">Transforming Healthcare Processes</a></h4>
<p>Vision GPT's unique capabilities offer significant benefits across various healthcare domains:</p>
<p><strong>Streamlined Data Ingestion:</strong></p>
<ul>
<li>Vision GPT can process complex medical documents like bills containing handwritten notes, extracting crucial information like dates, provider details, and disputed items.</li>
</ul>
<p><center>
  <img alt="Example Bill" src="/blogs/assets/vision-bill.png" />
</center>
<center>Doctor Notes Hand scribd </center></p>
<ul>
<li>This automated data extraction reduces manual effort and improves accuracy in pre-authorization and post-authorization processes.</li>
</ul>
<p><strong>Enhanced Bill Review:</strong></p>
<ul>
<li>
<p>Vision GPT can analyze medical bills, matching line items with medical codes, descriptions, and insurance policies.</p>
</li>
<li>
<p>It identifies covered services, deductibles, and potential discrepancies, streamlining the payment process and reducing errors.</p>
</li>
</ul>
<p><strong>Improved Patient Care:</strong>
  *  Vision GPT can assist in analyzing medical images, aiding radiologists in detecting abnormalities and supporting faster, more accurate diagnoses.</p>
<h4 id="addressing-concerns-and-ensuring-success"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#addressing-concerns-and-ensuring-success">Addressing Concerns and Ensuring Success</a></h4>
<p><strong>Model Maturity:</strong> Utilize Vision GPT models specifically pre-trained on healthcare and billing related datasets for optimal performance.</p>
<p><center>
<img alt="Example Bill" src="/blogs/assets/vision-maturity.png" />
</center>
<center> Trust Issues </center></p>
<p><strong>Trust and Control:</strong></p>
<ul>
<li>Avoid relying solely on public API only accessable generic models.</li>
<li>Prioritize deploying models locally and pretrain them with customer specific data to ensure complete control over features, versions and expected behavior.</li>
<li>Have strong Pen-Testing Capabilities built in to ensure these models cannot be comprimised by hidden OCR messages which are not visible to human, but will effect the automated decisions upstream. </li>
</ul>
<h4 id="conclusion"><a class="toclink" href="../../2024/07/19/gpt-vision-transformer/#conclusion">Conclusion</a></h4>
<p>Vision GPT holds immense promise for transforming healthcare by automating complex processes, improving accuracy, and empowering data-driven decision-making. </p>
<p>By addressing concerns and implementing best practices, healthcare organizations can leverage this powerful technology to enhance patient care, streamline operations, and ultimately achieve better outcomes.</p>
<p><strong>Credits : Unovie.AI</strong> is a specialized professional AI partner company with its unique UnoVie platform. We closely collaborate with our partners, leveraging their internal domain expertise to create value-driven outcomes within predictable timelines. We complement resources and design reliable, critical systems with explainability and transparency, adhering to strict privacy and regulatory security requirements. Our core strengths lie in MedTech and Industry 4.0 use cases. Learn more about us at https://unovie.ai.</p>
<p><strong>References</strong>
<a href="[](https://towardsdatascience.com/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8)">Phi-3-Vision</a>
<a href="https://medium.com/@liana.napalkova/fine-tuning-small-vision-language-models-phi-3-vision-b9d406e4e268">Fine-Tuning-Small-Vision-Model</a></p>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-07-06 00:00:00">Saturday, July 6, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">GENAI</a>, 
              <a href="../security/" class="md-meta__link">Security</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="google-genai-mis-usecases"><a class="toclink" href="../../2024/07/06/google-genai-mis-usecases/">Google GenAI Mis UseCases</a></h2>
<p>Generative Artificial Intelligence (GenAI), an advanced technology that has rapidly gained popularity, offers immense potential for creativity. However, as with any emerging technology, it also brings new security risks that require close attention to protect users from misuse and exploitation. In this article, we will delve into some key findings regarding the security risks associated with GenAI systems and discuss practical remediation strategies.</p>
<p>At XenVector we take Security very seriously, as much as we are excited like everybody in using <strong>GENAI to solve business productivity and efficencies</strong>, we also spend significant time to understand the <strong>Mis-UseCases and Threat Models</strong> to ensure our clients data is protected.</p>
<p><img alt="GenAI Misuse" src="/blogs/assets/genai-darkforce.jpg" /></p>
<p>Recently release Google research on AI mis-usecase highlights these concerns.</p>

    
      <nav class="md-post__action">
        <a href="../../2024/07/06/google-genai-mis-usecases/">
          Continue reading
        </a>
      </nav>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-07-06 00:00:00">Saturday, July 6, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">GENAI</a>, 
              <a href="../security/" class="md-meta__link">Security</a></li>
        
        
          
          <li class="md-meta__item">
            
              3 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="google-naptime-ai-vulnerability"><a class="toclink" href="../../2024/07/06/google-naptime-ai-vulnerability/">Google NapTime AI Vulnerability</a></h2>
<p>Google's <strong>Naptime enhances LLM's ability to identify and analyze vulnerabilities in a manner that is both accurate and reproducible while ensuring optimal performance through its specialized toolset</strong>. This innovative framework represents an important step forward for AI-assisted vulnerability research, allowing security experts and practitioners to streamline their workflow and focus on the most critical aspects of their work—and maybe even take a well-deserved nap or two!</p>
<p><img alt="Google Naptime" src="/blogs/assets/NaptimeArch.jpg" />
<center>Google Naptime Architecture </center></p>

    
      <nav class="md-post__action">
        <a href="../../2024/07/06/google-naptime-ai-vulnerability/">
          Continue reading
        </a>
      </nav>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-07-02 00:00:00">Tuesday, July 2, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">GENAI</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="microsoft-ai-graphrag"><a class="toclink" href="../../2024/07/02/microsoft-ai-graphrag/">Microsoft AI GraphRAG</a></h2>
<h3 id="enhancing-intelligent-applications-using-graphrag"><a class="toclink" href="../../2024/07/02/microsoft-ai-graphrag/#enhancing-intelligent-applications-using-graphrag">Enhancing Intelligent Applications using GraphRAG</a></h3>
<p>In today's rapidly evolving enterprise landscape, leveraging large language models (LLMs) to build AI-driven operations and intelligent applications is crucial for success. With the rise of private data sets within organizations, it becomes essential to establish clear relationships between various datasets using LLMs and Knowledge Graphs</p>
<p><img alt="Graphs vs RAG" src="/blogs/assets/llm-kg.png" />
<center>LLMs vs Knowledge Graphs</center></p>

    
      <nav class="md-post__action">
        <a href="../../2024/07/02/microsoft-ai-graphrag/">
          Continue reading
        </a>
      </nav>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.top", "navigation.tracking", "navigation.indexes", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>