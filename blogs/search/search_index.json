{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#unovie-blog","title":"UnoVie Blog","text":"<p>Follow us to Engineering Blog &lt;&lt;</p> <p>At UnoVie, we specialize in crafting cutting-edge artificial intelligence (AI) solutions tailored for small-medium enterprises (SMEs) within the healthcare and manufacturing sectors. Our services address unique business challenges by:</p> <p>Streamlining processes through automation of repetitive tasks to increase efficiency and reduce human error.</p> <p>Offering actionable insights driven by GENAI ML capabilities for informed decision-making that drives growth and improves customer satisfaction.</p> <p>Delivering highly personalized experiences across all touchpoints, ensuring client engagement and value throughout the project lifecycle.</p> <p>Optimizing costs through strategic resource allocation while continuously adapting to your evolving business needs.</p> <p>Don't miss out on the opportunity to unlock the transformative power of AI for your SME \u2013 contact Unovie today for a free architecture consultation or demo!</p>"},{"location":"blog/","title":"Articles","text":""},{"location":"blog/2024/07/21/apple-intelligence/","title":"Apple Intelligence","text":""},{"location":"blog/2024/07/21/apple-intelligence/#apple-intelligence-on-device-processing","title":"Apple Intelligence : On Device Processing","text":"<p>EdgeAI Privacy Innovation / Security Blueprint from Apple WWDC24 Conference</p> <p>Apple WWDC24 Keynote has some amazing GENAI Edge Innovation and brilliant engineering science on display which they talked about how on-device models that can outsource to Apple\u2019s servers. Most notable is their approach to features that don\u2019t work with an on-device model.</p> <p></p> <p>Apple WWDC24 Keynote : Apple Intelligence Reference YouTube video at 1h14m43s </p> <p>Apple</p> <p>When you make a request, Apple Intelligence analysis whether it can be processed on device. If it needs greater computational capacity, it can draw on Private Cloud Compute, and send only the data that\u2019s relevant to your task to be processed on Apple Silicon servers.</p> <p>Your data is never stored or made accessible to Apple. It\u2019s used exclusively to fulfill your request. And just like your iPhone, independent experts can inspect the code that runs on the servers to verify this privacy promise.</p> <p>In fact, Private Cloud Compute cryptographically ensures your iPhone, iPad, and Mac will refuse to talk to a server unless its software has been publicly logged for inspection.</p> <p>This sets a brand new standard on Privacy and AI</p>"},{"location":"blog/2024/07/21/apple-intelligence/#trust-user-privacy","title":"Trust : User Privacy","text":"<p>Trust of User Privacy is extremely important for every enterprise. Where it is HITRUST, FFIEC, FEDRAMP, NIST Standards. These security engineering privacy requirements should be the same every enterprise needs to adopt whether is Medical Device Manufacturer, Automotive EV Initiatives, HealthCare, Financial, Telecom Services, OTT providers Apple announcement is not too far from what GEHC has been working in MEDTECH world since last 4 years, Chief AI officer recently posted on Linkedin  \"GEHC Tops list for third year in row in highest number of AI-Enabled Medical Device Authorization\"</p>"},{"location":"blog/2024/07/21/apple-intelligence/#embracing-edge-ai-on-device-inferencing-a-strategic-imperative-for-enterprises","title":"Embracing Edge AI On-Device Inferencing: A Strategic Imperative for Enterprises","text":"<p>In today's rapidly evolving technological landscape, enterprises are increasingly recognizing the significance of Edge AI on-device inferencing as a key strategic initiative. The transition to Edge AI not only promises reduced operational expenses but also propels real-time decision-making capabilities. This shift is particularly pertinent given the limited access to high-end GPUs like the NVIDIA H100, which often ties enterprises into public cloud ecosystems, leading to skyrocketing operational expenditures (OPEX). Recent financial reports from NVIDIA and OpenAI echo this growing concern, underscoring the urgent need for cost-effective, yet powerful AI solutions.</p>"},{"location":"blog/2024/07/21/apple-intelligence/#the-demand-for-ai-embedded-software","title":"The Demand for AI-Embedded Software","text":"<p>The burgeoning demand for AI-embedded software, such as Microsoft's Copilot+, has showcased the transformative potential of AI in enhancing user interactions and automating complex tasks. These advanced AI systems leverage Edge NPU (Neural Processing Units), TPU (Tensor Processing Units), and GPU (Graphics Processing Units) to optimize data formatting in near real-time\u2014be it converting healthcare data into the FHIR format or standardizing payment data to ISO20022 benchmarks.</p>"},{"location":"blog/2024/07/21/apple-intelligence/#addressing-edge-npu-constraints","title":"Addressing Edge NPU Constraints","text":"<p>A critical challenge lies in the power and device constraints associated with Edge NPUs. Traditional Intel processors fall short, particularly in maintaining battery efficiency. However, recent advancements in computing hardware are closing this gap. Apple\u2019s M2 Pro and M3 chips have set new benchmarks in energy-efficient AI inferencing. Meanwhile, Qualcomm\u2019s Snapdragon X Elite, AMD\u2019s Ryzen AI, and Intel\u2019s Gaudi3, alongside a suite of ARM processors, are pioneering the next generation of powerful and energy-efficient NPU edge computing solutions.</p>"},{"location":"blog/2024/07/21/apple-intelligence/#real-time-decisions-in-the-physical-world","title":"Real-Time Decisions in the Physical World","text":"<p>Edge AI\u2019s potential shines brightest in real-world, real-time decision-making scenarios. Autonomous vehicles, for instance, rely on immediate safety decisions to protect passengers and pedestrians. In healthcare, an MRI scan identifying a brain hemorrhage can trigger an urgent alert to a surgical team, enhancing patient outcomes through timely interventions. Similarly, Apple\u2019s Siri exemplifies how AI can process device-specific information to make optimal decisions on behalf of users. These examples underscore the criticality of GEN-AI models\u2019 capability to operate both online and offline, ensuring seamless functionality in intermittently connected environments.</p>"},{"location":"blog/2024/07/21/apple-intelligence/#the-case-for-distributed-npu-mesh-and-joint-inferencing","title":"The Case for Distributed NPU Mesh and Joint Inferencing","text":"<p>Standalone models, while beneficial, often fall short in complex, real-world environments. For example, a Tesla vehicle utilizes a collective feed from eight cameras to inform its autonomous driving decisions, ensuring a comprehensive understanding of its surroundings. In the medical sector, an MRI machine's on-edge computing power might only yield a 60% confidence level in detecting a condition. Thus, the DICOM images must be transmitted to a nearby GPU cloud, leveraging extensive computational resources to reach near-100% diagnostic confidenc crucial for obtaining FDA Class III certification.</p> <p></p> <p>This leads us to the concept of distributed NPU mesh networks, where multiple models collaboratively enhance decision-making accuracy. This approach parallels human decision-making processes, where collective input often results in more accurate outcomes. Implementing a collective quorum of decision-making models allows for higher reliability and precision, pivotal in mission-critical applications.</p>"},{"location":"blog/2024/07/21/apple-intelligence/#conclusion","title":"Conclusion","text":"<p>Edge AI on-device inferencing represents a paradigm shift in enterprise strategy, promising enhanced real-time decision-making and cost efficiencies. The journey towards this vision involves embracing advanced NPU technologies, harnessing distributed inferencing models, and overcoming the limitations of traditional processors. With industry leaders like Apple, Qualcomm, AMD, and Intel setting new standards, the path towards a robust and cost-effective Edge AI ecosystem is clearer than ever.</p> <p>For enterprises, the strategic imperative is now to integrate these cutting-edge AI technologies into their core operations, driving innovation while safeguarding operational budgets. By doing so, businesses can unlock unprecedented levels of agility, accuracy, and efficiency, cementing their competitive edge in an increasingly AI-driven world.</p> <p>Credits : Unovie.AI  At Unovie.AI we strive to be your specialized professional AI partner, delivering unique AI solutions using our innovative private edge technology, the UnoVie platform. We offer engineering expertise and collaborate with partners to bring AI best practices to your organization. By leveraging your internal domain expertise, we create value-driven outcomes within predictable timelines. We complement your resources and build extremely reliable, safety critical AI systems with explainability and transparency. We adhere to strict data privacy and regulatory AI security requirements. Our core strengths lie in MedTech, BioSciences, Pharma and Industry 4.0 use cases.Learn more about us at https://unovie.ai.</p>"},{"location":"blog/2024/07/06/forrester-research-top-10-trends-2024/","title":"Forrester Research Top 10 Trends 2024","text":"<p>Top Ten Emerging Technologies in 2024 According to Forrester: Maximizing ROI and Addressing Security Concerns</p> <p>Forrester has identified ten emerging technologies that are expected to deliver significant returns on investment (ROI) within the next five years. These technologies will also play a crucial role in enhancing security measures across organizations. Here is an overview of Forrester's top ten emerging technologies:</p> <p></p> <p>Forrester's top ten emerging technologies provide valuable insights into advancements that will shape organizations in 2024. By focusing on these technologies and investing in robust security measures to protect their ROI potential, enterprises can stay ahead of the curve in this rapidly evolving landscape.</p> <p>GenAI for Visual Content and Language: Accelerating enterprise adoption through cloud-based apps and tools, genAI will have the potential to deliver ROI within two years in marketing, digital design, and communications sectors.</p> <p>TuringBots: AI-powered software robots that enhance application development by offering automation and semiautomated capabilities while providing assistive intelligence on code, processes, and applications. Expected ROI within two years.</p> <p>IoT Security: Essential for securing the increasing number of endpoint devices with familiar components such as asset management, identity access management (IAM), data security management, Zero Trust networking, and attack surface risk management. Anticipated to deliver expected business value within a year.</p> <p>AI Agents: Leveraging advanced deep learning techniques for greater context, analysis, strategy, and planning; Forrester predicts that organizations with large amounts of information and human workforces will see the biggest benefits in two to five years.</p> <p>Autonomous Mobility: Expected to improve operational efficiencies across shop floors, worker productivity and safety, supply chain management, and customer experience within two to three years.</p> <p>Quantum Security: Offering cryptographic agility for the future, enhancing digital signatures, and providing other benefits; Forrester anticipates quantum security will deliver ROI in over five years.</p> <p>Extended Reality (XR): While still developing adoption rates, XR technologies are expected to advance training and onboarding within five years or more.</p> <p>Zero Trust Edge (ZTE): Providing local security for remote workers, retail outlets, and branch offices; Forrester predicts that highly distributed enterprises will see the greatest benefit first in over five years.</p> <p>Cybersecurity Technologies: Including IoT Security, Quantum Security, and Zero Trust Edge as crucial components to maximize ROI while addressing security concerns across organizations.</p> <p>AI Zero Trust Framework: Emphasizing the importance of investing in security now with AI capabilities expanding and potential vulnerabilities increasing; Brian Hopkins highlights the need for a zero-trust framework, least privileged access enforcement, microsegmentation, and modern identity and access management systems.</p>"},{"location":"blog/2024/07/06/forrester-research-top-10-trends-2024/#xenvector-analysis","title":"XenVector Analysis","text":""},{"location":"blog/2024/07/19/gpt-vision-transformer/","title":"GPT Vision Transformer","text":""},{"location":"blog/2024/07/19/gpt-vision-transformer/#vision-ai-in-healthcare-streamlining-processes-and-empowering-decisions","title":"Vision AI in Healthcare: Streamlining Processes and Empowering Decisions","text":"<p>Let's explores the transformative potential of Vision AI, specifically Vision GPT, in revolutionizing healthcare operations.</p>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#understanding-vision-gpt","title":"Understanding Vision GPT","text":"<p>Vision GPT is a powerful pre-trained model that seamlessly integrates computer vision and natural language processing (NLP). It leverages a transformer architecture to analyze both visual and textual data simultaneously, unlocking a deeper understanding of the relationship between them.</p> <p></p> Vision Transformer Capabilities  <p>While existing large vision models excel in transfer learning, they often struggle when faced with various tasks and simple instructions. The challenge lies in handling spatial hierarchy and semantic granularity inherent in diverse vision-related tasks.</p> <p>Key challenges include the limited availability of comprehensive visual annotations and the absence of a unified pretraining framework with a singular neural network architecture seamlessly integrating spatial hierarchy and semantic granularity. Existing datasets tailored for specialized applications heavily rely on human labeling, which limits, the development of foundational models capable of capturing the intricacies of vision-related tasks.</p>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#vision-models","title":"Vision Models","text":"<p>Phi-3-Vision-128K-instruct</p> <p>Microsoft recently released Phi-3, a powerful language model, with a new Vision-Language variant called Phi-3-vision-128k-instruct. This 4B parameter model achieved impressive results on public benchmarks, even surpassing GPT-4V in some cases and outperforming Gemini 1.0 Pro V in all but MMMU.</p> <p>Florence-2</p> <p>Florence-2 is an advanced vision foundation model that uses a prompt-based approach to handle a wide range of vision and vision-language tasks. Florence-2 can interpret simple text prompts to perform tasks like captioning, object detection, and segmentation. It leverages our FLD-5B dataset, containing 5.4 billion annotations across 126 million images, to master multi-task learning. The model's sequence-to-sequence architecture enables it to excel in both zero-shot and fine-tuned settings, proving to be a competitive vision foundation model. </p> Florence 2 Vision Architecture  <p>Built by Microsoft, the Florence-2 model adopts a sequence-to-sequence architecture, integrating an image encoder and a multi-modality encoder-decoder. This design accommodates a spectrum of vision tasks without the need for task-specific architectural modifications, aligning with the ethos of the NLP community for versatile model development with a consistent underlying structure.</p> <p></p> A general vision model must be able to operate at various degrees of granularity, both spatial and semantic <p>Florence-2 stands out through its unprecedented zero-shot and fine-tuning capabilities, achieving new state-of-the-art results in tasks such as captioning, object detection, visual grounding, and referring expression comprehension. Even after fine-tuning with public human-annotated data, Florence-2 competes with larger specialist models, establishing new benchmarks. </p>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#key-capabilities","title":"Key Capabilities:","text":"<p>Object Recognition: Identifies objects within images (e.g., medical equipment, tumors, handwritten notes) using convolutional neural networks (CNNs) and transformer models.</p> <p></p> <p>Semantic Understanding: Connects visual concepts with corresponding words or phrases, accurately interpreting descriptions of scenes and objects.</p> <p></p> <p>Contextual Reasoning: Analyzes the context surrounding objects in images, discerning nuances often missed by traditional computer vision models.</p> <p></p>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#transforming-healthcare-processes","title":"Transforming Healthcare Processes","text":"<p>Vision GPT's unique capabilities offer significant benefits across various healthcare domains:</p> <p>Streamlined Data Ingestion:</p> <ul> <li>Vision GPT can process complex medical documents like bills containing handwritten notes, extracting crucial information like dates, provider details, and disputed items.</li> </ul> <p></p> Doctor Notes Hand scribd  <ul> <li>This automated data extraction reduces manual effort and improves accuracy in pre-authorization and post-authorization processes.</li> </ul> <p>Enhanced Bill Review:</p> <ul> <li> <p>Vision GPT can analyze medical bills, matching line items with medical codes, descriptions, and insurance policies.</p> </li> <li> <p>It identifies covered services, deductibles, and potential discrepancies, streamlining the payment process and reducing errors.</p> </li> </ul> <p>Improved Patient Care:   *  Vision GPT can assist in analyzing medical images, aiding radiologists in detecting abnormalities and supporting faster, more accurate diagnoses.</p>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#addressing-concerns-and-ensuring-success","title":"Addressing Concerns and Ensuring Success","text":"<p>Model Maturity: Utilize Vision GPT models specifically pre-trained on healthcare and billing related datasets for optimal performance.</p> <p></p>  Trust Issues  <p>Trust and Control:</p> <ul> <li>Avoid relying solely on public API only accessable generic models.</li> <li>Prioritize deploying models locally and pretrain them with customer specific data to ensure complete control over features, versions and expected behavior.</li> <li>Have strong Pen-Testing Capabilities built in to ensure these models cannot be comprimised by hidden OCR messages which are not visible to human, but will effect the automated decisions upstream. </li> </ul>"},{"location":"blog/2024/07/19/gpt-vision-transformer/#conclusion","title":"Conclusion","text":"<p>Vision GPT holds immense promise for transforming healthcare by automating complex processes, improving accuracy, and empowering data-driven decision-making. </p> <p>By addressing concerns and implementing best practices, healthcare organizations can leverage this powerful technology to enhance patient care, streamline operations, and ultimately achieve better outcomes.</p> <p>Credits : Unovie.AI is a specialized professional AI partner company with its unique UnoVie platform. We closely collaborate with our partners, leveraging their internal domain expertise to create value-driven outcomes within predictable timelines. We complement resources and design reliable, critical systems with explainability and transparency, adhering to strict privacy and regulatory security requirements. Our core strengths lie in MedTech and Industry 4.0 use cases. Learn more about us at https://unovie.ai.</p> <p>References Phi-3-Vision Fine-Tuning-Small-Vision-Model</p>"},{"location":"blog/2024/07/06/google-genai-mis-usecases/","title":"Google GenAI Mis UseCases","text":"<p>Generative Artificial Intelligence (GenAI), an advanced technology that has rapidly gained popularity, offers immense potential for creativity. However, as with any emerging technology, it also brings new security risks that require close attention to protect users from misuse and exploitation. In this article, we will delve into some key findings regarding the security risks associated with GenAI systems and discuss practical remediation strategies.</p> <p>At XenVector we take Security very seriously, as much as we are excited like everybody in using GENAI to solve business productivity and efficencies, we also spend significant time to understand the Mis-UseCases and Threat Models to ensure our clients data is protected.</p> <p></p> <p>Recently release Google research on AI mis-usecase highlights these concerns.</p> <p>Title: Understanding Security Risks in Generative AI (GenAI) Systems and Effective Remediation Strategies</p> <p>Introduction Generative Artificial Intelligence (GenAI), an advanced technology that has rapidly gained popularity, offers immense potential for creativity. However, as with any emerging technology, it also brings new security risks that require close attention to protect users from misuse and exploitation. In this article, we will delve into some key findings regarding the security risks associated with GenAI systems and discuss practical remediation strategies.</p>"},{"location":"blog/2024/07/06/google-genai-mis-usecases/#security-risks-in-generative-ai-systems","title":"Security Risks in Generative AI Systems","text":"<p>Misrepresentation: One of the major concerns is that malicious actors may manipulate GenAI to create deceptive content, such as deepfakes or synthetic media. These falsified representations can be used for personal attacks or defamation by impersonating public figures or private individuals and making false statements about them.</p> <p>Content Manipulation: Another risk is the generation of manipulated audio and video clips that could potentially harm content creators, journalists, or even celebrities. Attackers can use GenAI to create bogus news articles at scale, leading to misinformation and reputation damage.</p> <p>Intellectual Property Infringement: Malicious actors may also exploit GenAI capabilities for IP infringement by generating content that plagiarizes existing material or uses copyrighted data without permission, thereby undermining the rights of original creators.</p> <p>Digital Resurrection and Doxxing: With advancements in technology, attackers can create fake videos with deceased individuals narrating their experiences. Additionally, GenAI could be used for doxxing by revealing private information or creating synthetic identities that pose as legitimate users.</p>"},{"location":"blog/2024/07/06/google-genai-mis-usecases/#remediation-strategies-to-mitigate-security-risks","title":"Remediation Strategies to Mitigate Security Risks","text":"<p>Technical Safeguards: To tackle the misuse of GenAI systems, developers must take proactive measures such as removing toxic content from training data and restricting prompts that violate terms of service agreements. Implementing robust security measures at the technical level can help mitigate risks stemming from vulnerabilities in these systems.</p> <p>Non-Technical Interventions: It's crucial for users to understand their digital environment and identify potential phishing scams or misinformation campaigns. Prebunking, a psychological intervention that helps protect individuals against information manipulation, can be extended to GenAI-enabled tactics. This approach involves educating the public about common deceptive practices and encouraging critical thinking when interacting with AI-generated content.</p> <p>Continual Monitoring: As technology evolves and new capabilities emerge in GenAI systems, it is essential for researchers to conduct longitudinal analyses and keep track of the latest misuse tactics. By doing so, they can develop effective countermeasures against potential security threats that may arise as these technologies become more integrated into everyday applications and services.</p> <p>Collaborative Efforts: Lastly, it is vital for stakeholders such as developers, policymakers, researchers, and the public to work together in fostering a safe digital ecosystem where GenAI technology can thrive without posing undue risks to users' privacy and security.</p>"},{"location":"blog/2024/07/06/google-genai-mis-usecases/#conclusion","title":"Conclusion","text":"<p>As we continue to explore the immense potential of Generative AI systems, it is imperative that we remain vigilant about their associated security risks and implement appropriate remediation strategies. Through a combination of technical safeguards, non-technical interventsions, continual monitoring, and collaborative efforts, we can minimize the potential for misuse while ensuring GenAI technologies serve as powerful tools for innovation and creativity in the digital age.</p>"},{"location":"blog/2024/07/06/google-genai-mis-usecases/#google-research-paper","title":"Google Research Paper","text":""},{"location":"blog/2024/07/06/google-naptime-ai-vulnerability/","title":"Google NapTime AI Vulnerability","text":"<p>Google's Naptime enhances LLM's ability to identify and analyze vulnerabilities in a manner that is both accurate and reproducible while ensuring optimal performance through its specialized toolset. This innovative framework represents an important step forward for AI-assisted vulnerability research, allowing security experts and practitioners to streamline their workflow and focus on the most critical aspects of their work\u2014and maybe even take a well-deserved nap or two!</p> <p> </p>Google Naptime Architecture  <p>Since mid 2023 Google Researcher has been working on a framework for LLM assisted vulnerability research embodying these principles, with a particular focus on automating variant analysis. This project has been called \"Naptime\" because of the potential for allowing us to take regular naps while it helps us out with our jobs. Please don't tell our manager.</p> <p>Naptime uses a specialised architecture to enhance an LLM's ability to perform vulnerability research. A key element of this architecture is grounding through tool use, equipping the LLM with task-specific tools to improve its capabilities and ensure verifiable results. This approach allows for automatic verification of the agent's output, a critical feature considering the autonomous nature of the system.</p>"},{"location":"blog/2024/07/06/google-naptime-ai-vulnerability/#naptime-architecture","title":"Naptime architecture.","text":"<p>The Naptime architecture is centred around the interaction between an AI agent and a target codebase. The agent is provided with a set of specialised tools designed to mimic the workflow of a human security researcher.</p> <ul> <li> <p>Code Browser tool enables the agent to navigate through the target codebase, much like how engineers use Chromium Code Search. It provides functions to view the source code of a specific entity (function, variable, etc.) and to identify locations where a function or entity is referenced. While this capability is excessive for simple benchmark tasks, it is designed to handle large, real-world codebases, facilitating exploration of semantically significant code segments in a manner that mirrors human processes.</p> </li> <li> <p>Python tool enables the agent to run Python scripts in a sandboxed environment for intermediate calculations and to generate precise and complex inputs to the target program.</p> </li> <li> <p>Debugger tool grants the agent the ability to interact with the program and observe its behaviour under different inputs. It supports setting breakpoints and evaluating expressions at those breakpoints, enabling dynamic analysis. This interaction helps refine the AI's understanding of the program based on runtime observations. To ensure consistent reproduction and easier detection of memory corruption issues, the program is compiled with AddressSanitizer, and the debugger captures various signals indicating security-related crashes.</p> </li> <li> <p>Reporter tool provides a structured mechanism for the agent to communicate its progress. The agent can signal a successful completion of the task, triggering a request to the Controller to verify if the success condition (typically a program crash) is met. It also allows the agent to abort the task when unable to make further progress, preventing stagnation.</p> </li> </ul> <p>The system is model-agnostic and backend-agnostic, providing a self-contained vulnerability research environment. This environment is not limited to use by AI agents; human researchers can also leverage it, for example, to generate successful trajectories for model fine-tuning.</p> <p>Google's Naptime enables an LLM to perform vulnerability research that closely mimics the iterative, hypothesis-driven approach of human security experts. This architecture not only enhances the agent's ability to identify and analyse vulnerabilities but also ensures that the results are accurate and reproducible.</p>"},{"location":"blog/2024/07/02/microsoft-ai-graphrag/","title":"Microsoft AI GraphRAG","text":""},{"location":"blog/2024/07/02/microsoft-ai-graphrag/#enhancing-intelligent-applications-using-graphrag","title":"Enhancing Intelligent Applications using GraphRAG","text":"<p>In today's rapidly evolving enterprise landscape, leveraging large language models (LLMs) to build AI-driven operations and intelligent applications is crucial for success. With the rise of private data sets within organizations, it becomes essential to establish clear relationships between various datasets using LLMs and Knowledge Graphs</p> <p> </p>LLMs vs Knowledge Graphs <p> A prime example that highlights this need would be an incident management platform requiring a thorough understanding of error events and performance events to make accurate service circuit SLA decisions. Likewise, in enterprise security information and event management (SIEM) systems, correlating user identities with their access paths from logs is essential to identify anomalies effectively. The significance of using LLMs for these purposes has gained momentum through discussions within the research community. One such platform that embodies this approach is Microsoft's GraphRAG (Graph-based RAGnometries), which was announced in February 2024. GraphRAG offers an AI-driven content interpretation and search capability by utilizing LLMs to create a knowledge graph from private datasets, enabling users to query the data effectively for better results.</p>"},{"location":"blog/2024/07/02/microsoft-ai-graphrag/#graphrag-advantages","title":"GraphRAG Advantages","text":"<p>The major advantage of using Microsoft's GraphRAG over traditional vector search techniques is its ability to handle complex queries that demand higher order reasoning or extensive comprehension of the dataset at hand. For instance, when asked \"What are the most unusual conversations?\" a conventional vector search may fall short if it doesn't find an exact match in the data set. In contrast, GraphRAG builds a knowledge graph based on semantic concepts and provides a holistic understanding of all sources, allowing users to discover relevant information at various levels of abstraction for more accurate retrieval-augmented generation tasks.</p> <p></p> <p>Google Cloud has similar GraphRAG implementation using Neo4J </p> <p>GraphRAG can be employed across critical information discovery and analysis use cases where datasets span multiple documents or contain noise, mixed with misinformation, or when the user's queries are abstract or thematic in nature. Furthermore, it is designed to complement a domain expert's analytical approach rather than replace their insights altogether.</p> <p>The GraphRAG process begins by indexing an input corpus into analyzable TextUnits and extracting entities, relationships, and key claims using LLMs. This information undergoes hierarchical clustering via the Leiden technique to create a visual graph representation of entities. From there, summaries are generated for each community and its constituents from bottom-up, enabling users to gain comprehensive insights into their dataset.</p> <p>When querying GraphRAG's knowledge graph, users can employ two primary modes: global search for holistic questions about the corpus or local search for specific entities by exploring related concepts within their neighborhood. It is worth noting that fine-tuning prompts using Microsoft's Prompt Tuning Guide may be necessary to achieve optimal results when working with your data set.</p>"},{"location":"blog/2024/07/02/microsoft-ai-graphrag/#architecture","title":"Architecture","text":"Architecture diagram shows how Google Cloud and Neo4j work together to build and interact with knowledge graphs <ul> <li> <p>Knowledge extraction - On the left side of the diagram, blue arrows show data flowing from structured and unstructured sources into Vertex AI. Generative AI is used to extract entities and relationships from that data which are then converted to Neo4j Cypher queries that are run against the Neo4j database to populate the knowledge graph. This work was traditionally done manually with handcrafted rules. Using generative AI eliminates much of the manual work of data cleansing and consolidation.</p> </li> <li> <p>Knowledge consumption - On the right side of the diagram, green arrows show applications that consume the knowledge graph. They present natural language interfaces to users. Vertex AI generative AI converts that natural language to Neo4j Cypher that is run against the Neo4j database. This allows non technical users to interact more closely with the database than was possible without generative AI</p> </li> </ul>"},{"location":"blog/2024/07/02/microsoft-ai-graphrag/#usecases","title":"UseCases","text":"<p>We\u2019re seeing this architecture come up again and again across verticals. Some examples include:</p> <ul> <li> <p>Healthcare - Modeling the patient journey for multiple sclerosis to improve patient outcomes</p> </li> <li> <p>Manufacturing - Using generative AI to collect a bill of materials that extends across domains, something that wasn\u2019t tractable with previous manual approaches</p> </li> <li> <p>Oil and gas - Building a knowledge base with extracts from technical documents that users without a data science background can interact with. This enables them to more quickly educate themselves and answer questions about the business.</p> </li> </ul>"},{"location":"blog/2024/07/02/microsoft-dapr-zero-trust/","title":"Microsoft Dapr Zero Trust","text":""},{"location":"blog/2024/07/02/microsoft-dapr-zero-trust/#dapr-zero-trust-security-for-distributed-applications","title":"Dapr : Zero Trust Security for Distributed Applications","text":"<p>Dapr improves the zero trust security posture of distributed systems out of the box by assigning application identities to all apps, ensuring that mTLS is enabled by default for all interservice and infrastructure communication.</p> <p>The standards around security in software development are ever increasing in response to the need for greater protection. This article looks at the open source project Dapr, distributed application runtime, which contains a rich security feature set that allows developers to \u201cshift left\u201d with security and embed industry-standard best practices into their applications during development. Dapr provides a set of APIs to solve common distributed systems challenges around state management, workflow and data.</p> <p> </p>Dapr Security  Architecture <p> </p>Dapr Deployment Architecture vm-physical-containers  <p></p>"},{"location":"capability/aiops/","title":"AIOPS Deck.","text":""},{"location":"capability/aiops/#aiops-deck","title":"AIOPS Deck.","text":""},{"location":"capability/brochure/","title":"Full Capability Deck.","text":""},{"location":"capability/brochure/#full-capability-deck","title":"Full Capability Deck.","text":""},{"location":"capability/dc300/","title":"EdgeAI DataCenter DC300.","text":""},{"location":"capability/dc300/#edgeai-datacenter-dc300","title":"EdgeAI DataCenter DC300.","text":"<p>Unovie Edge-AI DC200 operates as a far edge gateway with 4G LTE connectivity in numerous sectors such as healthcare, automotive, and industrial fields. It functions as a gateway to connect to Cloud hosted Control plane in AWS/Azure/GCP and connected via Ethernet to other FarEdge Applications in the TPU-Mesh for offloading critical zero-trust, network and security functions</p> <p></p> <p>Furthermore, it accommodates comprehensive local private deployment capabilities that cater to AI algorithms with high computing needs including models like Llama3, Gemma2 and Mistral or YOLOv8 object detection models. </p> <p>The system is fully controlled through an API from the Cloud Control Plane and smartly integrates with other Edge Gateways for shared Tensor Processing Unit (TPU) resource utilization.</p>"},{"location":"capability/dc300/#platform-capabilities","title":"Platform Capabilities","text":"<ul> <li> <p>Modern and loosely coupled microservices architecture that is hardware and operating system agnostic</p> </li> <li> <p>Advanced integration with multiple OT device protocols including Modbus, BACnet, MQTT, OPC UA, BLE, Zigbee, EtherCAT, PROFINET and many more, with a Device SDK to create further connectors</p> </li> </ul> <p></p> <ul> <li> <p>Integration with multiple IT and Cloud systems including AWS, Google Cloud\u00a0IoT, Microsoft Azure, IBM Watson\u00a0IoT\u00a0and more, with an Application SDK to create your own</p> </li> <li> <p>Provision of edge analytics, decision making, control and visualization with standard APIs and the capability to easily integrate more Critical security features to preserve the safe running of the platform</p> </li> <li> <p>Advanced system tooling to fast-track the development, testing, deployment and administration of the platform \u00a0</p> </li> </ul>"},{"location":"capability/dc300/#edge-intelligence","title":"Edge Intelligence","text":"<p>EdgeAI DC300 has enough NPU computing power which can stacked up incrementally to support LLM and GPT Models Industry 4.0 usecases.</p> <ul> <li> <p>Making machines smarter: Predicting failures, optimizing processes, and improving quality control through data analysis.</p> </li> <li> <p>Simplifying human-machine interaction: Using natural language for easier control and training.</p> </li> <li> <p>Unlocking data insights: Extracting valuable information from vast amounts of data for better decision-making.</p> </li> <li> <p>Streamlining supply chains: Predicting demand, managing suppliers, and improving efficiency.</p> </li> <li> <p>Boosting security and compliance: Automating documentation and detecting threats.</p> </li> </ul> <p></p>"},{"location":"capability/dc300/#specifications","title":"Specifications","text":""},{"location":"capability/fe100/","title":"Edge-AI FarEdge FE100.","text":""},{"location":"capability/fe100/#edge-ai-faredge-fe100","title":"Edge-AI FarEdge FE100.","text":"<p>Unovie Edge-AI FE100 operates as a far edge box in numerous sectors such as healthcare, automotive, and industrial fields. It functions as a Far Edge Gateway connected to Ethernet networks for efficient low latency application delivery, maintaining less than 3 seconds of latency by being closer to the data sources. </p> <p></p> <p>Furthermore, it accommodates comprehensive local private deployment capabilities that cater to AI algorithms with high computing needs including models like Llama3, Gemma2 and Mistral or YOLOv8 object detection models. </p> <p>The system is fully controlled through an API from the Cloud Control Plane and smartly integrates with other Edge Gateways for shared Tensor Processing Unit (TPU) resource utilization.</p>"},{"location":"capability/fe100/#platform-capabilities","title":"Platform Capabilities","text":"<ul> <li> <p>Modern and loosely coupled microservices architecture that is hardware and operating system agnostic</p> </li> <li> <p>Advanced integration with multiple OT device protocols including Modbus, BACnet, MQTT, OPC UA, BLE, Zigbee, EtherCAT, PROFINET and many more, with a Device SDK to create further connectors</p> </li> <li> <p>Integration with multiple IT and Cloud systems including AWS, Google Cloud\u00a0IoT, Microsoft Azure, IBM Watson\u00a0IoT\u00a0and more, with an Application SDK to create your own</p> </li> <li> <p>Provision of edge analytics, decision making, control and visualization with standard APIs and the capability to easily integrate more Critical security features to preserve the safe running of the platform</p> </li> <li> <p>Advanced system tooling to fast-track the development, testing, deployment and administration of the platform \u00a0</p> </li> </ul>"},{"location":"capability/fe100/#edge-intelligence","title":"Edge Intelligence","text":"<p>Application Capabilities. - Asset Tracking - Intelligent Mobile Routing - Plant Floor Automation - Temperature Monitoring - Service Observability Gateway  - Anomaly Detection with Incident Event Collection</p> <p>EdgeAI FE100 supports up to 32 channels of 1080P H.264/H.265 video decoding and 32 channels of 1080P HD video processing (decoding + AI analysis),making it ideal for various AI applications such as face detection and license plate recognition on video streaming.</p> <p></p>"},{"location":"capability/fe100/#specifications","title":"Specifications","text":""},{"location":"capability/gw200/","title":"EdgeAI Gateway GW200.","text":""},{"location":"capability/gw200/#edgeai-gateway-gw200","title":"EdgeAI Gateway GW200.","text":"<p>Unovie Edge-AI GW200 operates as a far edge gateway with 4G LTE connectivity in numerous sectors such as healthcare, automotive, and industrial fields. It functions as a gateway to connect to Cloud hosted Control plane in AWS/Azure/GCP and connected via Ethernet to other FarEdge Applications in the TPU-Mesh for offloading critical zero-trust, network and security functions</p> <p></p> <p>Furthermore, it accommodates comprehensive local private deployment capabilities that cater to AI algorithms with high computing needs including models like Llama3, Gemma2 and Mistral or YOLOv8 object detection models. </p> <p>The system is fully controlled through an API from the Cloud Control Plane and smartly integrates with other Edge Gateways for shared Tensor Processing Unit (TPU) resource utilization.</p>"},{"location":"capability/gw200/#platform-capabilities","title":"Platform Capabilities","text":"<ul> <li> <p>Modern and loosely coupled microservices architecture that is hardware and operating system agnostic</p> </li> <li> <p>Advanced integration with multiple OT device protocols including Modbus, BACnet, MQTT, OPC UA, BLE, Zigbee, EtherCAT, PROFINET and many more, with a Device SDK to create further connectors</p> </li> <li> <p>Integration with multiple IT and Cloud systems including AWS, Google Cloud\u00a0IoT, Microsoft Azure, IBM Watson\u00a0IoT\u00a0and more, with an Application SDK to create your own</p> </li> <li> <p>Provision of edge analytics, decision making, control and visualization with standard APIs and the capability to easily integrate more Critical security features to preserve the safe running of the platform</p> </li> <li> <p>Advanced system tooling to fast-track the development, testing, deployment and administration of the platform \u00a0</p> </li> </ul>"},{"location":"capability/gw200/#edge-intelligence","title":"Edge Intelligence","text":"<p>EdgeAI FE100 supports up to 32 channels of 1080P H.264/H.265 video decoding and 32 channels of 1080P HD video processing (decoding + AI analysis),making it ideal for various AI applications such as face detection and license plate recognition on video streaming.</p> <p>Application Capabilities. - Asset Tracking - Intelligent Mobile Routing - Temperature Monitoring - Service Observability Gateway  - Anomaly Detection with Incident Event Collection</p> <p></p>"},{"location":"capability/gw200/#specifications","title":"Specifications","text":""},{"location":"blog/category/genai/","title":"GENAI","text":""},{"location":"blog/category/security/","title":"Security","text":""},{"location":"blog/category/medtech/","title":"MedTech","text":""},{"location":"blog/category/market-trends/","title":"Market Trends","text":""},{"location":"blog/category/platform-engineering/","title":"Platform Engineering","text":""}]}