{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome","title":"Welcome","text":"<p>Welcome to Unovie.AI a AI Edge computing platform.</p>"},{"location":"#ground-principles","title":"Ground Principles","text":"<p>Few ground rules you need to aware as your working with the larger team.</p> <ul> <li>Git is the source of truth, we all will be having local sandbox environments but in the end we converge in github<ul> <li>everything and anything you do have to be committed onto git and that's how you collabrate. No code update on git means no work done.</li> </ul> </li> <li>Linux is your local working environment.<ul> <li>everybody can install there local sandbox by following these instructions.</li> <li>your local sandbox is personal to you, and it allows you to try all your changes locally before you commit them into git.</li> <li>everything we do will be packaged as docker container, so it can be deployed on target exactly the same way it was tested in sandbox.</li> <li>AI and Cloud has no windows experience, so as programmer you are expected to master linux, so get comfortable with it sooner.</li> </ul> </li> <li>API is how we talk <ul> <li>Learn REST and OPENAPI standards.</li> <li>Anything data you need to share with another system or container has to be REST API</li> </ul> </li> <li>SQL is DataScience.<ul> <li>Expecting you master your SQL skills, we will be using postgres database </li> <li>Jupyter Notebook to run python programs </li> </ul> </li> </ul> <p>We need you favor to improve this documentation. Please volunteer yourself if you can help make this better or post us some comments on Zulip Channel of what changes you like to see and we will update it for you.</p> <p>Cheers.</p>"},{"location":"domains/manufacturing/","title":"Manufacturing Domain","text":""},{"location":"domains/manufacturing/#manufacturing-domain","title":"Manufacturing Domain","text":""},{"location":"domains/manufacturing/#usecases","title":"UseCases","text":"<ul> <li>Uber Delivery for Trucks : Manufacturing Truck Loading and Delivery </li> <li>Testing</li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/","title":"Palette Tracking","text":""},{"location":"domains/manufacturing/pallete-tracking/#palette-tracking","title":"Palette Tracking","text":""},{"location":"domains/manufacturing/pallete-tracking/#manufacturing-delivery-system-for-truck-drivers","title":"Manufacturing Delivery System for Truck Drivers","text":"<p>Prompt : You are AI/ML expert in Manufacturing Domain. Your goal is to develop Vision AI use-cases using YOLOv8 or Yolov10 and OpenCV technology for the business problem I provide.  Try to keep the context specific to the problem I provide and provide step by step guidance analysis of the use case. Don't Hallucinate and be as accurate as possible</p> <p>UseCase : As a Bottling company, I need a business process model to optimize my truck delivery as it's outsourced to third party providers. From the time the truck came to the factory, to the time the tuck is loading palette to the time the truck drops off the goods I need a Uber like application which can help me tracking the delivery efficiency. It is expected there will be cameras with ANPR and Bar code scanners available within the Factory premises. But also we will have Smart Mobile Application which will provide driver tracking and assistance. Think through the specific details on how to build a solution around these requirements     </p> <p>Here's a breakdown of a business process model for optimizing truck deliveries at your bottling company, incorporating real-time tracking, driver assistance, and efficiency analysis:</p>"},{"location":"domains/manufacturing/pallete-tracking/#system-architecture-plan-1","title":"System Architecture : Plan 1","text":"<p>Backend:</p> <ul> <li> <p>Database: Store truck details, driver information, delivery schedules, order details, GPS data, and camera/scanner readings.</p> </li> <li> <p>API:  Provides interfaces for mobile app, web dashboard, and integration with external systems (e.g., ERP).</p> </li> <li> <p>Analytics Engine: Processes real-time and historical data to generate reports on delivery efficiency, bottlenecks, and driver performance.</p> </li> </ul> <p>Mobile App (Driver):</p> <ul> <li> <p>GPS Tracking: Real-time location updates, route guidance, and estimated time of arrival (ETA).</p> </li> <li> <p>Delivery Management: Receive and confirm delivery assignments, update delivery status, and capture proof of delivery (e.g., photos, signatures).</p> </li> <li> <p>Communication: In-app messaging for communication with dispatchers and customers.</p> </li> </ul> <p>Web Dashboard (Admin):</p> <ul> <li> <p>Real-Time Tracking:  Visualize truck locations on a map, track delivery progress, and monitor driver performance.</p> </li> <li> <p>Delivery Management:  Assign deliveries, manage schedules, and track order fulfillment.</p> </li> <li> <p>Analytics &amp; Reporting: Generate reports on delivery efficiency, bottlenecks, driver performance, and customer satisfaction.</p> </li> </ul> <p>Camera System (Factory):</p> <ul> <li> <p>ANPR:  Capture license plate numbers of arriving trucks.</p> </li> <li> <p>Barcode Scanner:  Scan barcodes on delivery documents and pallets for verification.</p> </li> <li> <p>Integration:  Feed data to the backend system for automatic truck registration, order matching, and inventory updates.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#business-process-flow","title":"Business Process Flow","text":"<p>Truck Arrival:</p> <ul> <li> <p>Driver arrives at the factory and the ANPR camera captures the truck's license plate.</p> </li> <li> <p>The system automatically identifies the truck based on its license plate and retrieves its details from the database.</p> </li> </ul> <p>Order Verification:</p> <ul> <li> <p>The driver presents the delivery documents to the barcode scanner.</p> </li> <li> <p>The barcode scanner reads the document and confirms the order details with the system.</p> </li> </ul> <p>Loading Process:</p> <ul> <li> <p>The system provides a loading plan based on the order details and truck capacity.</p> </li> <li> <p>The driver uses the mobile app to confirm the loading process and update the system on the number of pallets loaded.</p> </li> </ul> <p>Departure:</p> <ul> <li> <p>Once the loading is complete, the driver confirms departure through the mobile app.</p> </li> <li> <p>The system updates the delivery status and sends a notification to the customer.</p> </li> </ul> <p>Delivery:</p> <ul> <li> <p>The driver navigates to the delivery location using the mobile app's GPS tracking and route guidance.</p> </li> <li> <p>Upon delivery, the driver captures proof of delivery (e.g., photo, signature) and updates the delivery status.</p> </li> </ul> <p>Post-Delivery:</p> <ul> <li> <p>The system generates a delivery report, including time taken, distance covered, and any issues encountered.</p> </li> <li> <p>The analytics engine processes the data to identify trends and areas for improvement.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#technology-stack","title":"Technology Stack","text":"<ul> <li> <p>Backend: Python (Flask or Django), PostgreSQL, Redis</p> </li> <li> <p>Mobile App: React Native (cross-platform), Flutter (cross-platform)</p> </li> <li> <p>Analytics: Apache Spark, Tableau, Power BI</p> </li> <li> <p>Camera System: OpenCV/YoloV8 for ANPR, barcode scanning libraries</p> </li> <li> <p>GPS Tracking: Google Maps API, Mapbox</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#benefits","title":"Benefits","text":"<ul> <li> <p>Real-Time Visibility: Track truck locations and delivery progress in real-time.</p> </li> <li> <p>Improved Efficiency: Optimize loading and routing processes, reduce delivery times.</p> </li> <li> <p>Enhanced Customer Experience: Provide accurate ETAs and delivery updates.</p> </li> <li> <p>Data-Driven Insights: Identify bottlenecks, performance issues, and areas for improvement.</p> </li> <li> <p>Cost Savings: Reduce fuel consumption, labor costs, and potential delays.</p> </li> </ul> <p>This model provides a framework for building your Uber-like truck delivery system. Remember to tailor it to your specific needs, resources, and existing infrastructure.</p>"},{"location":"domains/manufacturing/pallete-tracking/#system-architecture-plan-2","title":"System Architecture : Plan 2","text":"<p>Based on your requirements, I'll outline a business process model and a technical architecture for optimizing truck delivery efficiency using Vision AI, ANPR, barcode scanners, and a smart mobile application.</p>"},{"location":"domains/manufacturing/pallete-tracking/#business-process-model","title":"Business Process Model:","text":"<ul> <li> <p>Pre-Arrival: The truck arrives at the factory, and the driver checks-in through the mobile application.</p> </li> <li> <p>Vehicle Identification: The ANPR camera captures the truck's license plate number, which is used to identify the vehicle and retrieve relevant information (e.g., schedule, cargo details).</p> </li> <li> <p>Security Check: The barcode scanner verifies that the arriving truck matches the scheduled delivery, ensuring that no unauthorized vehicles enter the premises.</p> </li> <li> <p>Loading: The driver loads the palettes onto the truck using a forklift or other equipment. During this process, cameras installed at strategic locations within the factory can track the loading progress.</p> </li> <li> <p>Departure: Once loaded, the truck departs from the factory.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#technical-architecture","title":"Technical Architecture:","text":"<p>To build an Uber-like application that tracks delivery efficiency, we'll leverage the following technologies:</p> <ul> <li> <p>Computer Vision (CV):</p> <p>Use OpenCV with YOLOv8 or Yolov10 for object detection (e.g., pallets, trucks) and tracking.</p> <p>Integrate CV models with ANPR and barcode scanner data to enhance accuracy.</p> </li> <li> <p>ANPR:</p> <p>Utilize a commercial-grade ANPR solution (e.g., Genetec, 3xLOGIC) that provides accurate license plate recognition and vehicle identification.</p> </li> <li> <p>Barcode Scanning:</p> <p>Leverage a high-quality barcode scanner (e.g., Honeywell, Datalogic) to verify truck identifications.</p> </li> <li> <p>Mobile Application:</p> <p>Develop a user-friendly mobile app for drivers to check-in, navigate the factory, and track their delivery progress.</p> </li> <li> <p>Server-Side Infrastructure:</p> <p>Build a scalable server-side infrastructure using technologies like Node.js, Express.js, or Django to handle data storage, processing, and API management.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#data-flow","title":"Data Flow:","text":"<ul> <li>Camera feed from ANPR and CV cameras</li> <li>Barcode scanner data (truck identification)</li> <li>Mobile application check-in and location updates</li> <li>Server-side data processing and analysis using YOLOv8/Yolov10 models</li> <li>Real-time tracking and display of delivery progress on a dashboard or map view</li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#key-performance-indicators-kpis","title":"Key Performance Indicators (KPIs):","text":"<ul> <li> <p>Delivery Time: Track the time taken for trucks to arrive, load, and depart from the factory.</p> </li> <li> <p>Loading Efficiency: Measure the percentage of palettes loaded correctly within a specified timeframe.</p> </li> <li> <p>Driver Compliance: Monitor driver adherence to scheduled routes, loading procedures, and safety guidelines.</p> </li> </ul> <p>This architecture provides a solid foundation for building an efficient delivery tracking system that leverages Vision AI, ANPR, barcode scanners, and mobile applications. By implementing this solution, your bottling company can optimize truck delivery efficiency, reduce costs, and improve overall customer satisfaction.</p>"},{"location":"domains/manufacturing/pallete-tracking/#statement-of-work","title":"Statement of Work","text":"<p>Here's a detailed project plan that can be used to create a Statement of Work (SOW) for the development of an Uber-like application for truck delivery tracking and optimization:</p> <p>Project Title: Truck Delivery Tracking and Optimization System</p>"},{"location":"domains/manufacturing/pallete-tracking/#project-description","title":"Project Description:","text":"<p>The goal of this project is to design, develop, and deploy an application that tracks and optimizes truck deliveries within our bottling company's factory premises. The system will utilize computer vision (CV) technology with YOLOv8 or Yolov10 for object detection and tracking, ANPR for vehicle identification, and barcode scanning for verification.</p>"},{"location":"domains/manufacturing/pallete-tracking/#scope-of-work","title":"Scope of Work:","text":"<ul> <li> <p>Computer Vision (CV) Component</p> <p>Develop a CV model using YOLOv8 or Yolov10 to detect and track pallets within the factory premises.</p> <p>Integrate CV models with ANPR data to enhance accuracy.</p> <p>Install and configure cameras at strategic locations within the factory for real-time monitoring.</p> </li> <li> <p>ANPR Component</p> <p>Utilize a commercial-grade ANPR solution (e.g., Genetec, 3xLOGIC) to identify vehicles arriving at the factory premises.</p> <p>Integrate ANPR data with CV models to verify vehicle identifications.</p> </li> <li> <p>Barcode Scanning Component</p> <p>Leverage a high-quality barcode scanner (e.g., Honeywell, Datalogic) to verify truck identifications.</p> <p>Integrate barcode scanning data with CV and ANPR data for seamless verification.</p> </li> <li> <p>Mobile Application Component</p> <p>Develop a user-friendly mobile app for drivers to check-in, navigate the factory, and track their delivery progress.</p> </li> <li> <p>Server-Side Infrastructure</p> <p>Build a scalable server-side infrastructure using technologies like Node.js, Express.js, or Django to handle data storage, processing, and API management.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#integration-and-testing","title":"Integration and Testing","text":"<ul> <li> <p>Integrate all components (CV, ANPR, barcode scanning, mobile app) for seamless operation.</p> </li> <li> <p>Conduct thorough testing to ensure system reliability, accuracy, and performance.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#deliverables","title":"Deliverables:","text":"<ul> <li> <p>System Design Documentation: Comprehensive documentation of the system architecture, including CV models, ANPR integration, barcode scanning, and mobile application design.</p> </li> <li> <p>CV Model Training Data: High-quality training data for YOLOv8 or Yolov10 model development.</p> </li> <li> <p>ANPR Configuration Files: Configured ANPR solution files for seamless integration with CV models.</p> </li> <li> <p>Barcode Scanning Configuration Files: Configured barcode scanning files for seamless integration with CV and ANPR data.</p> </li> <li> <p>Mobile Application Source Code: Source code for the mobile application developed using a suitable programming language (e.g., Java, Swift).</p> </li> <li> <p>Server-Side Infrastructure Code: Server-side infrastructure code developed using technologies like Node.js, Express.js, or Django.</p> </li> <li> <p>System Testing Report: Comprehensive report detailing system testing results, including accuracy, reliability, and performance metrics.</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#timeline","title":"Timeline:","text":"<ul> <li>Week 1-4: System design documentation and CV model development</li> <li>Week 5-8: ANPR integration and barcode scanning configuration</li> <li>Week 9-12: Mobile application development and server-side infrastructure development</li> <li>Week 13-16: Integration and testing of all components</li> <li>Week 17: Final system deployment and training</li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#assumptions-and-dependencies","title":"Assumptions and Dependencies:","text":"<ul> <li> <p>Access to Factory Premises: Access to the factory premises for camera installation and testing.</p> </li> <li> <p>ANPR Solution Availability: Availability of a commercial-grade ANPR solution (e.g., Genetec, 3xLOGIC).</p> </li> <li> <p>Barcode Scanning Solution Availability: Availability of high-quality barcode scanning equipment (e.g., Honeywell, Datalogic).</p> </li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#acceptance-criteria","title":"Acceptance Criteria:","text":"<ul> <li> <p>System Accuracy: System accuracy in detecting and tracking pallets within the factory premises.</p> </li> <li> <p>ANPR Verification: Successful verification of vehicle identifications using ANPR data.</p> </li> <li> <p>Barcode Scanning Verification: Seamless integration with barcode scanning data for truck identification.</p> </li> <li> <p>Mobile Application Functionality: User-friendly mobile application that allows drivers to check-in, navigate the factory, and track their delivery progress.</p> </li> </ul> <p>This project plan provides a detailed outline of the scope of work, deliverables, timeline, assumptions, dependencies, and acceptance criteria required for the development of an Uber-like application for truck delivery tracking and optimization.</p>"},{"location":"domains/manufacturing/pallete-tracking/#business-process-management-bpm","title":"Business Process Management (BPM)","text":"<p>Camunda is a popular open-source workflow engine that allows organizations to model, execute, and improve business processes using the BPMN (Business Process Model and Notation) standard. Here's how Camunda can help automate the truck delivery tracking and optimization process:</p>"},{"location":"domains/manufacturing/pallete-tracking/#process-modeling","title":"Process Modeling:","text":"<p>Define the Process: Use Camunda's modeling tools to create a visual representation of the truck delivery process, including all steps, decisions, and interactions.</p> <p>Model the Process Flow: Define the sequence of activities, such as:</p> <ul> <li>Truck arrival at the factory</li> <li>ANPR verification</li> <li>Barcode scanning verification</li> <li>CV model execution for pallet detection</li> <li>Mobile app notifications for drivers</li> </ul> <p>Automation:</p> <ul> <li>Task Automation: Automate tasks, such as:</li> <li>Triggering the ANPR system upon truck arrival</li> <li>Executing the barcode scanner to verify truck identification</li> <li>Initiating the CV model to detect and track pallets</li> </ul> <p>Decision Management: Implement decision logic to determine next steps based on process conditions, such as:</p> <ul> <li>If the truck is verified, proceed with unloading and pallet detection</li> <li>If an issue occurs during verification, escalate to a supervisor for assistance</li> </ul>"},{"location":"domains/manufacturing/pallete-tracking/#integration","title":"Integration:","text":"<p>System Integration: Integrate Camunda with other systems, including:</p> <ul> <li>ANPR system for vehicle identification</li> <li>Barcode scanning equipment for truck identification</li> <li>CV model for pallet detection</li> <li>Mobile app for driver notifications and updates</li> </ul> <p>API-based Integrations: Use APIs to integrate with external systems, allowing seamless data exchange between Camunda and other applications</p>"},{"location":"domains/manufacturing/pallete-tracking/#monitoring-and-analytics","title":"Monitoring and Analytics:","text":"<p>Process Monitoring: Track process performance in real-time using Camunda's built-in monitoring capabilities.</p> <p>Analytics and Reporting: Generate reports on process metrics, such as:</p> <ul> <li>Average processing time for truck deliveries</li> <li>Error rates for ANPR verification and barcode scanning</li> <li>Pallet detection accuracy</li> </ul> <p>Benefits:</p> <ul> <li>Improved Efficiency: Automate manual tasks and reduce errors.</li> <li>Increased Transparency: Provide real-time visibility into the delivery process.</li> <li>Enhanced Decision Making: Support data-driven decision-making with analytics and reporting.</li> </ul> <p>To implement Camunda in this use case, you would need to:</p> <ul> <li>Model the truck delivery process using Camunda's BPMN editor.</li> <li>Configure task automation, decision management, and system integration according to the process model.</li> <li>Deploy the process to the Camunda engine for execution.</li> <li>Monitor and analyze process performance using Camunda's built-in monitoring and analytics capabilities.</li> </ul> <p>By leveraging Camunda's workflow engine, you can streamline and automate the truck delivery tracking and optimization process, improving efficiency, transparency, and decision-making within your organization.</p>"},{"location":"setup/dify/","title":"GEN-AI DIFY Dev platform with Ollama","text":""},{"location":"setup/dify/#gen-ai-dify-dev-platform-with-ollama","title":"GEN-AI DIFY Dev platform with Ollama","text":""},{"location":"setup/dify/#dify-gen-ai-framework","title":"DIFY GEN-AI Framework","text":"<p>Dify is an open-source LLM app development platform. Orchestrate LLM apps from agents to complex AI workflows, with an RAG engine.</p> <p>More production-ready than LangChain.</p> <p>You can find more information about </p> <p>DIFY at there website</p> <p>DIFY Blogs</p>"},{"location":"setup/dify/#ollama-llm-api-server","title":"Ollama LLM API Server","text":"<p>Ollama is API Server compatible with OPENAI clients and allows you to run local LLM models   </p> <p>Run Llama 3.1, Phi 3, Mistral, Gemma 2, and other models. Customize and create your own</p> <p>Read more about it at </p> <p>Ollama Blog</p> <p>Ollama Models</p> <p>For the sandbox we already downloaded and installed ollama in docker container and it's part of DIFY docker-compose.</p> <p>Also we downloaded 2 models in it.</p> <ul> <li>text-embedding : all-minilm:l6-v2</li> <li>chat : gemma2:2b-instruct-q2_K (alias uv-gemma2)</li> </ul> <p>As the name says text-embedding models support creating of embeddings from provided text, and chat or completion models is gemma2, 2 Billion parameter model with instruct trained dataset and quantized for low memory requirements.</p> <p>Given the virtual machine memory limitations in the sandbox we will not load a larger memory.</p>"},{"location":"setup/dify/#configuring-dify-to-use-ollama-models","title":"Configuring DIFY to use OLLAMA models","text":"<p>Following are instructions to configure DIFY to use the local LLM models, typically the DIFY examples are configured to OpenAI which requires special API-Token and Cost is involved.</p> <p>Open your browser and access the website on the VM IP address http://</p> <p>It should redirect you to create a admin userid and password for the first time. Once you finish that login into the Server using the id and password.</p> <p>On Login. Select the UserID Settings</p> <ul> <li> <p>User &gt; Settings </p> </li> <li> <p>Settings &gt; Model Provider     </p> </li> <li> <p>From Models select &gt; Ollama Provider</p> <p>Select LLM   Model Name : uv-gemma2   Base URL : http://ollama:11434</p> <p></p> </li> <li> <p>Models &gt; Model Provider      Now you should see the model is available on the main settings menu.</p> <p></p> </li> <li> <p>Let's add one more embedding model using ollama itself.</p> <p>Click on Add model</p> <p>Select : Text Embeddings  Model Name : all-minilm:l6-v2 Base URL : http://ollama:11434</p> <p></p> </li> <li> <p>If all goes well you should see 2 models under ollama</p> <p></p> </li> <li> <p>Now make these as default one for System Model Settings </p> <p></p> </li> </ul> <p>This should conclude setting up the models and your ready for workshop lab project. If you come across any issues report issue on Zulip support channel and we can figure out what went wrong.</p>"},{"location":"setup/linux-sandbox/","title":"Linux sandbox","text":""},{"location":"setup/linux-sandbox/#developer-sandbox-setup-for-linux","title":"Developer Sandbox Setup for Linux","text":"<p>You sir, are already enlightned for using Linux desktop.</p> <p>The instructions are very simple. Make sure the following are installed</p> <ul> <li>Miniconda with Python 3.11</li> <li>Docker, Docker-compose</li> <li>VSCode or equivalent. </li> <li>Git</li> <li>DIFY</li> <li>OLLMA Server</li> </ul> <p>There are some specific docker-compose capabilities we tweaked look at the sandbox.sh script and follow the instructions.</p> <pre><code>apt-get -y -qq install curl\nclear\nbash &lt;(curl -s https://unovie.ai/docs/assets/sandbox.sh)\nbash &lt;(curl -s https://unovie.ai/docs/assets/update.sh)\n</code></pre> <p>Do me a favor can you update the sandbox.sh script to and modify it to check if your operating out of WSL2 in native Linux Environment and deploy things as required.</p> <p>Send me the updated script in Zulip. - Suresh</p>"},{"location":"setup/wsl2-sandbox/","title":"Wsl2 sandbox","text":""},{"location":"setup/wsl2-sandbox/#developer-sandbox-setup","title":"Developer Sandbox Setup","text":"<p>Welcome to Unovie, AI platform for Edge. </p> <p>To make it easier for developer's we intend to provide a sandbox environment so it's easier to get consistent learning experiences.</p> <p>Please follow these instructions and let us know how we can improve this documentation for future newbie's. Your feedback is very important to us.</p>"},{"location":"setup/wsl2-sandbox/#linux-vm-install","title":"Linux VM Install.","text":"<p>To install Windows Subsystem for Linux (WSL) version 2 with Ubuntu 24.04 LTS on Windows 10, follow the steps below:</p> <p>Step 1: Update Windows to the latest version and enable Developer Mode</p> <p>Go to Settings &gt; Update &amp; Security &gt; Windows Update, then click Check for updates and install any available updates.</p> <p>Once your system is up-to-date, go back to Settings &gt; Update &amp; Security &gt; For developers, and ensure that \"Developer mode\" is turned on. If not, switch it on by clicking the toggle button. You may be prompted to restart your computer after enabling Developer Mode.</p> <p>Step 2: Enable Virtual Machine Platform feature (Optional) This step ensures a smoother installation process for WSL2 and is recommended if you are using Windows build 19041 or later, which comes with the May 2020 Update (version 2004). To enable this feature:</p> <p>Press Win + X and select \"Windows PowerShell (Admin)\" from the menu that appears. This will open a new Windows PowerShell window with admin privileges.</p> <p>In the PowerShell window, run the following command to enable the Virtual Machine Platform feature: </p><pre><code>Enable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform -All\n</code></pre> Restart your computer after enabling the Virtual Machine Platform feature if prompted. <p>Step 3: Install WSL2</p> <p>Open a Windows PowerShell with administrative privileges as described in step 2 of Step 2.</p> <p>Run the following command to enable the WSL2 Linux kernel feature (this is only required for versions prior to Windows build 19041):</p> <pre><code>dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n</code></pre> <p>Restart your computer when prompted. After the restart, open a PowerShell window again with administrative privileges and run these commands to install WSL2:</p> <pre><code>wsl --install -d Ubuntu-24.04\n</code></pre> <p>Step 4: Set up default user for Ubuntu on WSL2 After installing the Ubuntu distribution, you may want to create a new user account within it and set it as your default user. Here's how to do this:</p> <p>Launch the Ubuntu distribution by typing wsl in the Windows search bar or running the command  </p><pre><code>wsl -d Ubuntu-24.04\n</code></pre> <p>Once you are logged into the Ubuntu environment, open a terminal window and run these commands to create a new user account: </p><pre><code>sudo adduser unovie\n</code></pre> <p>Set your default password during the username creation process. After creating the user, log out from your current session (you can do this by typing exit or pressing Ctrl + D), and then run the following command to set it as your default Ubuntu user: </p><pre><code>wsl --set-default-user unovie -d Ubuntu-24.04\n</code></pre> <p>Now, every time you launch WSL with wsl or from the Windows search bar, you'll be logged in to your new user account by default.</p> <p>Step 5: Update and upgrade packages Once you have set up Ubuntu on WSL2, it is a good idea to update and upgrade all installed packages to ensure that everything is running smoothly:</p> <p>Run the following commands in the Ubuntu terminal window to update your package lists and then install any available updates: </p><pre><code>sudo apt-get update\nsudo apt-get upgrade -y\n</code></pre> <p>Congratulations! You have successfully installed WSL2 with Ubuntu 24.04 LTS on Windows 10, and you can now start using the Linux environment right from your Windows machine.</p>"},{"location":"setup/wsl2-sandbox/#windows-terminal","title":"Windows Terminal","text":"<p>Install Windows Terminal which allows you to work with WSL2 easily </p> <p>Follow this link to install https://apps.microsoft.com/detail/9n0dx20hk701?rtc=1&amp;hl=en-us&amp;gl=US</p>"},{"location":"setup/wsl2-sandbox/#install-sandbox-packages","title":"Install Sandbox Packages","text":"<p>In terminal execute the following script </p> <pre><code>apt-get -y -qq install curl\nclear\nbash &lt;(curl -s https://unovie.ai/docs/assets/sandbox.sh)\nbash &lt;(curl -s https://unovie.ai/docs/assets/update.sh)\n</code></pre> <p>Now follow the instructions to setup DIFY to support ollama model.</p>"},{"location":"training/about-unovie/","title":"About unovie","text":""},{"location":"training/about-unovie/#about-unovie","title":"About Unovie","text":"<p>Welcome to Unovie, AI platform for Edge. </p> <p>Unovie Mission : </p> <ul> <li>Apply AI to Edge use-cases in real-world where latency and decision taking is near real-time (less than 30sec)</li> <li>In-line with Stream Processing of Data NOT Batch Processing</li> <li>Have capability to AI-Mesh of sharing the limited GPU resources (Similar to Apple Intelligence)</li> <li>Solid Engineering Skills to help customers solve business problems with end-to-end design, build, operate projects at large scale.</li> <li>Extreme Automation and Laser focused project delivery within fixed time and fixed costs.</li> </ul> <p>Some important links you need to aware of</p> <ul> <li>Blogs : Unovie Blogs  have important public facing innovation ideas distilled to non-technical users.</li> <li>Apple Intelligence has been captured in blog and highlights the on-device processing, tensor parallelism, model co-processing </li> </ul> <p>Unovie Introduction </p>"},{"location":"training/ai-evolution/","title":"Ai evolution","text":""},{"location":"training/ai-evolution/#tracking-the-ai-evolution","title":"Tracking the AI Evolution","text":"<p>Knowledge in itself is a incremental evolution of foundational things set before</p> <p>Like evolution of DNA which has fine-tunes itself over millions of years to be what it is.  example my Dog Jasmine learnt that giving love and loyalty means good food and happy life.</p>"},{"location":"training/ai-evolution/#ai-evolution","title":"AI Evolution.","text":"<ul> <li> <p>AI had lot of false starts, since early 2000's their have been various things attempted and failed miserably. Example IBM talked about WATSON and it was total disaster. Company's spend millions of dollars on Hadoop and it's a total failure.</p> </li> <li> <p>Phoenix from Ashes. Great things come out when it's dust and no hope (Kalki 2898 AD Humor). Google Generative Pre-trained Transformer (GPT) invented by Google Deepmind engineers in 2017 changed the world for ever with their research paper \"Attention is All you need\" . If you want to watch a video to get 101 knowledge following this Youtube video: Attention Mechanism Overview. It's predicted it will be Noble Price Winning sometime in future but at least as Engineers let's honor that they shared this wisdom to the wider world that now OpenSource is able to innovate and not call it Black Magic </p> </li> </ul>"},{"location":"training/ai-evolution/#public-speaking","title":"Public Speaking","text":"<p>Following are the slides, I presented in Cloud-Austin Meetup in Aug and Oct 2024, although my goal was the teach the audience about How to Protect Intellectual Property in AI models for Large Enterprises, I had to skim through knowledge for audience to get them up to speed, so they know why it has to be protected.</p> <p>Enjoy these slides. Connect me on LinkedIn and give me a reference if you like enjoyed this content. </p> <p>AI Trust and Security Risk Management </p>"},{"location":"training/dify-sandbox-project/","title":"Dify sandbox project","text":""},{"location":"training/dify-sandbox-project/#dify-sandbox-project","title":"DIFY Sandbox project.","text":""},{"location":"training/dify-sandbox-project/#goal-create-a-genai-api-application","title":"Goal : Create a GENAI API Application","text":"<p>The intent is to create a Generative AI Application, which can leverage DIFY Orchestrator and Ollama to build a simple consumer application. </p> <p>What are you learning : </p> <ul> <li>Creating a quick proto-type application using pre-build DIFY templates</li> <li>Configuring Model and Environments to figure out how the platform interactions work.</li> <li>Get exposure to using AGENTS to interact in external API's.</li> <li>Get exposure to prompting on how to set the framework of conversation </li> <li>Get exposure to doing RAG (Retrieval Argument Generation) from the data upload (PDF/Image/CSV)</li> <li>Get exposure to publish a simple REST APP and interact with it using JSON request and response.</li> <li>Eventually we expect you to fine tune the model at later time. But you will have to learn everything required to do this prior to </li> </ul>"},{"location":"training/dify-sandbox-project/#architecture","title":"Architecture","text":"<p>We are yet to decide on the front end application framework. Please watch out for his article for updates as we expect to publish that shortly.</p>"},{"location":"training/dify-sandbox-project/#sandbox-setup","title":"SandBox Setup","text":"<p>Please follow instructions to setup SANDBOX environment using these instructions</p>"},{"location":"training/dify-sandbox-project/#rules","title":"Rules","text":"<ul> <li>Everybody will have there own application built, they will not pick the same project template. It is expected you will expand beyond standard template used.</li> <li>Everything you do will have to published in GIT repo. (GIT URL will be published shortly)</li> <li>You will have to document the process in versions. Create a markdown file with intent, changes your making in every version as part of your code commit. </li> <li>No documentation or code update means no progress, have not done anything. We expect you to have issues / problems and workarounds which needs to be published int he Zulip &gt; Learning-AI - Hands on Lab Topic.  </li> <li>Repeat here again, We need to capture your notes in Markdown and publish it in git on where / what your working on. </li> </ul>"},{"location":"training/dify-sandbox-project/#create-2-ai-applications","title":"Create 2 AI Applications.","text":"<p>MyAI Chat application: which can is optimized to answer your questions, From how to build a application to what ideas work best and where do you start. In short this is your personal Advisor Coach which helps you learn how to navigate the waters when no human is around.</p> <p>MyProject Application: This is the project sample application your building which is published in GitHub. Make sure your project is unique.</p>"},{"location":"training/dify-sandbox-project/#timeline","title":"Timeline","text":"<ul> <li>1 week end-to-end includes front end web application. </li> <li>Demo Show and Tell date : Aug 26, 2024</li> </ul>"},{"location":"training/embeddings-transformers/","title":"Embeddings transformers","text":""},{"location":"training/embeddings-transformers/#embeddings","title":"Embeddings","text":"<p>Embeddings are a fundamental concept in natural language processing (NLP). </p> <p>In essence, embeddings are numerical representations of words, phrases, or even entire documents.</p> <p>Think of them as a way to translate human language into a format that computers can understand and process. </p> <p>Here's a breakdown:     Each word or concept is assigned a unique vector (a list of numbers).     Words with similar meanings or contexts will have vectors that are closer together in this \"embedding space.\"</p> <p>Why are embeddings so powerful?</p> <p>Capturing semantic relationships: Embeddings allow us to see the relationships between words beyond just their literal definitions. For example, \"king\" and \"queen\" would be closer together than \"king\" and \"banana.\"</p> <p>Improved performance in NLP tasks: Embeddings are used in a wide range of NLP applications, such as:</p> <ul> <li>Text classification: Categorizing documents into predefined categories.</li> <li>Sentiment analysis: Determining the emotional tone of a piece of text.</li> <li>Machine translation: Automatically translating text from one language to another.</li> <li>Text generation: Creating new text that is coherent and grammatically correct.</li> </ul> <p>Types of Embeddings:</p> <p>There are various types of embeddings, each with its own strengths and weaknesses. Some popular ones include:</p> <ul> <li> <p>Word2Vec: A widely used technique that learns embeddings from large text corpora.</p> </li> <li> <p>GloVe (Global Vectors for Word Representation): Another popular method that leverages global word co-occurrence statistics.</p> </li> <li> <p>BERT (Bidirectional Encoder Representations from Transformers): A more advanced technique that considers the context of words in both directions.</p> </li> </ul> <p>Text Embeddings</p> <p>Embeddings What are they and why they matter</p>"},{"location":"training/embeddings-transformers/#transformers-gpt-generative-pre-processing-transformer","title":"Transformers : GPT : Generative Pre-Processing Transformer","text":"<p>Generative:  This means it's designed to create new text, not just analyze existing text. You can think of it as a very advanced chatbot that can write stories, poems, articles, and more.</p> <p>Pre-trained: GPT models are trained on massive amounts of text data before they are released. This pre-training allows them to learn the patterns and rules of language, giving them a broad understanding of how words work together.</p> <p>Transformer: This refers to the specific type of neural network architecture used in GPT. Transformers are particularly good at handling sequential data like text because they can consider the context of words in a sentence.</p> <p>Transformer Explainer. This is a very neat interactive visualization (with accompanying essay and video - scroll down for those) that explains the Transformer architecture for LLMs, using a GPT-2 model running directly in the browser using the ONNX runtime and Andrej Karpathy's nanoGPT project.</p> <p>Transfomer Explainer</p>"},{"location":"training/market-analyst/","title":"Market analyst","text":""},{"location":"training/market-analyst/#industry-analysts-predictions-on-ai","title":"Industry Analysts Predictions on AI","text":"<p>Enterprise CIO/CEO's listen to what Gartner, Forrester Research, McKensey is saying to decide how to align their business needs.</p> <p>Following are the snapshot of articles which highlight what these business leaders are listening too.</p>"},{"location":"training/market-analyst/#why-is-this-important-how-does-this-effect-me","title":"Why is this important How does this effect me","text":"<ul> <li>Every company decision to spend money, hire people, fire people is based on these market analysts predictions.</li> <li>It is very important you are aware of catching these signals to make you career decisions.</li> <li>Surely CNN / FoxNews / Times of India don't give you clarity in what's happening in technology world.</li> <li>Like stock traders who carefully make choices in terms of what to buy and sell, we at Unovie use this signals to build the right technology for the right customer needs and right time. :). </li> <li>You are team Unovie and this will be expected than a common man who has no knowledge about what truely a model is and talks random things with no comprehension how it effects their life.</li> <li>Customers are hiring us for this innovation, leadership, vision, execution excellence. Let's be humble learning these.</li> </ul>"},{"location":"training/market-analyst/#ai-wisdom","title":"AI Wisdom","text":"<p>An economist has said, \"AI won't take your job, it's somebody using AI that will take your job.\" AI seems to be a positive for many workers, but some roles are more at risk of replacement. Experts advise skilling up and leaning into soft human skills as AI becomes embedded in work life.</p>"},{"location":"training/market-analyst/#gartner-2024-predictions","title":"Gartner 2024 Predictions","text":""},{"location":"training/market-analyst/#gartner-2024-ai-hypecycle","title":"Gartner 2024 AI HypeCycle","text":""},{"location":"training/market-analyst/#mckensey-state-of-ai-quantumblack","title":"McKensey State of AI : QuantumBlack","text":"<p>Mckensey State of AI</p>"},{"location":"training/model-tuning/","title":"Model tuning","text":"<p>AI Fine-tuning, Quantization  </p>"},{"location":"training/postgresML/","title":"postgresML","text":""},{"location":"training/postgresML/#postgresml","title":"PostGresML","text":""},{"location":"training/postgresML/#graphrag","title":"GraphRAG","text":"<p>GraphRAG is a structured, hierarchical approach to Retrieval Augmented Generation (RAG), as opposed to naive semantic-search approaches using plain text snippets. The GraphRAG process involves extracting a knowledge graph out of raw text, building a community hierarchy, generating summaries for these communities, and then leveraging these structures when perform RAG-based tasks.</p> <p>GraphRAG Tutorial</p>"},{"location":"training/postgresML/#postgresml_1","title":"PostGresML","text":"<p>Postgres with GPU's for ML/AI Apps</p> <ul> <li>Index, filter &amp; rank vectors</li> <li>Create embeddings</li> <li>Generate real-time, fact-based outputs</li> </ul> <p>Why ? </p> <ul> <li>OpenSource</li> <li>Listen to the Founder </li> <li>32 Minutes Video</li> <li>Highly recommend viewing it </li> </ul> <p>Youtube Video : Simplify End-To-End MLOps with PostgresML - Montana Low, PostgresML</p> <p>PostgresML Website PostgresML Website</p>"},{"location":"training/postgresML/#training-collatral","title":"Training Collatral","text":"<p>Presentation Material for Aug 27,2024</p> <p>PostGresML - GraphRAG  </p>"}]}